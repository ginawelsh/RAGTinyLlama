{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21786b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/giwe7005/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2477a84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alessandro', 'volta', 'improv', 'popular', 'electrophoru']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess textual input --> tokens\n",
    "\n",
    "def tokenize(string_input):\n",
    "     string_input = re.sub(r'\\W+', ' ', string_input)\n",
    "     string_input = string_input.lower()\n",
    "     tk = WordPunctTokenizer()\n",
    "     tokens = tk.tokenize(string_input)\n",
    "     stop_words = set(stopwords.words('english'))\n",
    "     stemmer = PorterStemmer()\n",
    "     clean_tokens = []\n",
    "     for token in tokens:\n",
    "          if token.isalpha() and token not in stop_words:\n",
    "               clean_tokens.append(stemmer.stem(token))\n",
    "     return clean_tokens\n",
    "\n",
    "tokenize(\"When did Alessandro Volta improve  and popularize the electrophorus???\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CORPUS - extract files and create a dictionary of each file and their contents \n",
    "# {key = document_id: value = tokenised contents of document}\n",
    "\n",
    "import json\n",
    "\n",
    "def create_corpus():\n",
    "    corpus = dict()\n",
    "    for file in os.listdir(path=\"group_project/text_data\"):\n",
    "            # take only files with .clean suffix\n",
    "            if file.endswith(\".clean\"):\n",
    "                f = open(os.path.join(\"group_project/text_data\", file), encoding=\"latin-1\")\n",
    "                file_name = file.strip(\".txt.clean\")\n",
    "                # gives the contents of each document just in string form\n",
    "                file_contents = f.read()\n",
    "                # tokenize contents of files\n",
    "                tokens = tokenize(file_contents)\n",
    "                # assign tokenize contents to file name entry in corpus\n",
    "                corpus[file_name] = tokens\n",
    "    return corpus\n",
    "\n",
    "# create corpus \n",
    "corpus = create_corpus()\n",
    "\n",
    "len(corpus)\n",
    "\n",
    "# print example of corpus entry\n",
    "corpus[\"S08_set4_a8\"]\n",
    "corpus[\"S09_set4_a8\"]\n",
    "corpus[\"S08_set1_a1\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad04ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27374"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vocabulary, i.e. unique set of tokens that occur across all documents in corpus\n",
    "\n",
    "def create_vocabulary(corpus):\n",
    "     vocabulary = set()\n",
    "     for file in corpus:\n",
    "          for token in corpus[file]:\n",
    "               # add token to vocabulary set \n",
    "               vocabulary.add(token)\n",
    "     return sorted(vocabulary) # must be in a particular order \n",
    "\n",
    "def is_clean_token(token):\n",
    "    return re.match(r\"^[a-zA-Z\\-]+$\", token) is not None\n",
    "\n",
    "# preprocess textual input --> tokens\n",
    "\n",
    "create_vocab = create_vocabulary(corpus) # create unique set of terms that occur across all documents, n = 42,729\n",
    "\n",
    "vocabulary = [token for token in create_vocab if is_clean_token(token)] # clean out strange vocabulary items\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0022d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document frequency dictionary - number of documents a given token appears in\n",
    "# currently takes 3m 35s to run\n",
    "\n",
    "document_frequency = {token: 0 for token in vocabulary}\n",
    "\n",
    "for token in vocabulary:\n",
    "    for document in corpus:\n",
    "     if token in corpus[document]:\n",
    "          document_frequency[token] += 1\n",
    "\n",
    "\n",
    "document_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a65dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output document frequency to json file\n",
    "\n",
    "import json\n",
    "\n",
    "with open('document_frequency.json', 'w') as json_file:\n",
    "    json.dump(document_frequency, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative code (to speed things up): load document frequency from json file\n",
    "\n",
    "with open('document_frequency.json', 'r') as json_file:\n",
    "    document_frequency = json.load(json_file)\n",
    "\n",
    "#document_freq_df = pd.DataFrame(list(data.items()), columns=['word', 'count'])\n",
    "\n",
    "document_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7edea0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>4.317488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aafc</th>\n",
       "      <td>4.317488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aag</th>\n",
       "      <td>4.317488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aalto</th>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaltonen</th>\n",
       "      <td>4.317488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwischen</th>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwoll</th>\n",
       "      <td>4.317488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zygomat</th>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zygoptera</th>\n",
       "      <td>4.317488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>4.317488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27374 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           IDF Score\n",
       "aaa         4.317488\n",
       "aafc        4.317488\n",
       "aag         4.317488\n",
       "aalto       3.912023\n",
       "aaltonen    4.317488\n",
       "...              ...\n",
       "zwischen    3.912023\n",
       "zwoll       4.317488\n",
       "zygomat     3.912023\n",
       "zygoptera   4.317488\n",
       "zz          4.317488\n",
       "\n",
       "[27374 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-compute idf scores using document frequency dictionary\n",
    "\n",
    "def calculate_idf(term, corpus_dictionary):\n",
    "     \"\"\"calculate inverted document frequency\"\"\"\n",
    "     idf = math.log(len(corpus_dictionary)/((document_frequency[term])+1)) # can replace w/frequency count \n",
    "     return idf\n",
    "\n",
    "\n",
    "idf_scores = {}\n",
    "\n",
    "for item in vocabulary:\n",
    "     if item not in idf_scores:\n",
    "          idf_scores[item] = calculate_idf(item, corpus)\n",
    "          #print(idf_scores[item])\n",
    "\n",
    "\n",
    "# turn corpus into pandas dataframe\n",
    "idf_df_scores = pd.DataFrame.from_dict(idf_scores, orient='index', columns=['IDF Score'])\n",
    "\n",
    "idf_df_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b33a56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S08_set4_a8</th>\n",
       "      <th>S09_set4_a8</th>\n",
       "      <th>S10_set4_a8</th>\n",
       "      <th>S10_set5_a5</th>\n",
       "      <th>S08_set3_a7</th>\n",
       "      <th>S10_set6_a3</th>\n",
       "      <th>S10_set6_a2</th>\n",
       "      <th>S09_set3_a4</th>\n",
       "      <th>S09_set1_a5</th>\n",
       "      <th>S08_set2_a7</th>\n",
       "      <th>...</th>\n",
       "      <th>S10_set2_a4</th>\n",
       "      <th>S08_set1_a9</th>\n",
       "      <th>S08_set1_a8</th>\n",
       "      <th>S09_set2_a4</th>\n",
       "      <th>S08_set2_a3</th>\n",
       "      <th>S09_set1_a1</th>\n",
       "      <th>S09_set3_a6</th>\n",
       "      <th>S09_set3_a2</th>\n",
       "      <th>S09_set4_a5</th>\n",
       "      <th>S08_set4_a5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amedeo</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avogadro</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caricatur</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lorenzo</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romano</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniondal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cve</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lha</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peanut</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pepperidg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27374 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           S08_set4_a8  S09_set4_a8  S10_set4_a8  S10_set5_a5  S08_set3_a7  \\\n",
       "amedeo               5            5            3            0            0   \n",
       "avogadro            33           33           30            0            0   \n",
       "caricatur            1            1            0            1            1   \n",
       "lorenzo              1            1            1            0            0   \n",
       "romano               1            1            1            0            0   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "uniondal             0            0            0            0            0   \n",
       "cve                  0            0            0            0            0   \n",
       "lha                  0            0            0            0            0   \n",
       "peanut               0            0            0            0            0   \n",
       "pepperidg            0            0            0            0            0   \n",
       "\n",
       "           S10_set6_a3  S10_set6_a2  S09_set3_a4  S09_set1_a5  S08_set2_a7  \\\n",
       "amedeo               0            0            0            0            0   \n",
       "avogadro             0            0            0            0            0   \n",
       "caricatur            1            0            0            0            0   \n",
       "lorenzo              9           16            2            1            0   \n",
       "romano               0            0            0            0            2   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "uniondal             0            0            0            0            0   \n",
       "cve                  0            0            0            0            0   \n",
       "lha                  0            0            0            0            0   \n",
       "peanut               0            0            0            0            0   \n",
       "pepperidg            0            0            0            0            0   \n",
       "\n",
       "           ...  S10_set2_a4  S08_set1_a9  S08_set1_a8  S09_set2_a4  \\\n",
       "amedeo     ...            0            0            0            0   \n",
       "avogadro   ...            0            0            0            0   \n",
       "caricatur  ...            0            0            0            0   \n",
       "lorenzo    ...            0            0            0            0   \n",
       "romano     ...            0            0            0            0   \n",
       "...        ...          ...          ...          ...          ...   \n",
       "uniondal   ...            0            0            0            0   \n",
       "cve        ...            0            0            0            0   \n",
       "lha        ...            0            0            0            0   \n",
       "peanut     ...            0            0            0            0   \n",
       "pepperidg  ...            0            0            0            0   \n",
       "\n",
       "           S08_set2_a3  S09_set1_a1  S09_set3_a6  S09_set3_a2  S09_set4_a5  \\\n",
       "amedeo               0            0            0            0            0   \n",
       "avogadro             0            0            0            0            0   \n",
       "caricatur            0            0            0            0            0   \n",
       "lorenzo              0            0            0            0            0   \n",
       "romano               0            0            0            0            0   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "uniondal             0            0            0            2            0   \n",
       "cve                  0            0            0            1            0   \n",
       "lha                  0            0            0            1            0   \n",
       "peanut               0            0            0            1            0   \n",
       "pepperidg            0            0            0            1            0   \n",
       "\n",
       "           S08_set4_a5  \n",
       "amedeo               0  \n",
       "avogadro             0  \n",
       "caricatur            0  \n",
       "lorenzo              0  \n",
       "romano               0  \n",
       "...                ...  \n",
       "uniondal             0  \n",
       "cve                  0  \n",
       "lha                  0  \n",
       "peanut               0  \n",
       "pepperidg            0  \n",
       "\n",
       "[27374 rows x 150 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# TERM FREQUENCY MATRIX - PER DOCUMENT\n",
    "# create term-document-matrix - every document converted to a vector corresponding to frequency of each vocab item appearing in that document\n",
    "\n",
    "def term_document_matrix(corpus, vocab):\n",
    "       data = {}\n",
    "       for doc_id, tokens in corpus.items():\n",
    "              freqs = Counter(tokens)\n",
    "              for term, count in freqs.items():\n",
    "                     if term in vocab:\n",
    "                            if term not in data:\n",
    "                                   data[term] = {}\n",
    "                            data[term][doc_id] = count\n",
    "       df = pd.DataFrame.from_dict(data, orient='index').fillna(0).astype(int)  \n",
    "       return df\n",
    "\n",
    "\n",
    "term_document_matrix = term_document_matrix(corpus, vocabulary)\n",
    "\n",
    "term_document_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78359f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tf values\n",
    "\n",
    "def calculate_tf(term, document, term_document_matrix):\n",
    "     \"\"\"calculate term frequency\"\"\"\n",
    "     tf = term_document_matrix[term][document]/len(document) # tf = vocab_index[term, document] / len(document)\n",
    "     return tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather doc ids\n",
    "doc_ids = [file.strip(\".txt.clean\") for file in os.listdir(path=\"group_project/text_data\") if file.endswith('.clean')]\n",
    "\n",
    "# initialise pandas dataframe\n",
    "tfidf_df = pd.DataFrame(0.0, index=vocabulary, columns=doc_ids) \n",
    "\n",
    "# create tf idf calculation vectors for each token in vocabulary, for each doc in corpus\n",
    "def doc_vectorise(doc_ids, corpus, vocabulary):\n",
    "    for doc in doc_ids:\n",
    "        counts = Counter(corpus[doc])\n",
    "        for term, freq in counts.items():\n",
    "            if term in vocabulary:\n",
    "                # calculate tf_idf\n",
    "                term_document_matrix.loc[term, doc] = (freq / len(corpus[doc])) * idf_scores[term] # or use another tf scheme\n",
    "    return term_document_matrix\n",
    "\n",
    "tf_idf_docs_vector = doc_vectorise(doc_ids, corpus, vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62ba79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S08_set4_a8</th>\n",
       "      <th>S09_set4_a8</th>\n",
       "      <th>S10_set4_a8</th>\n",
       "      <th>S10_set5_a5</th>\n",
       "      <th>S08_set3_a7</th>\n",
       "      <th>S10_set6_a3</th>\n",
       "      <th>S10_set6_a2</th>\n",
       "      <th>S09_set3_a4</th>\n",
       "      <th>S09_set1_a5</th>\n",
       "      <th>S08_set2_a7</th>\n",
       "      <th>...</th>\n",
       "      <th>S10_set2_a4</th>\n",
       "      <th>S08_set1_a9</th>\n",
       "      <th>S08_set1_a8</th>\n",
       "      <th>S09_set2_a4</th>\n",
       "      <th>S08_set2_a3</th>\n",
       "      <th>S09_set1_a1</th>\n",
       "      <th>S09_set3_a6</th>\n",
       "      <th>S09_set3_a2</th>\n",
       "      <th>S09_set4_a5</th>\n",
       "      <th>S08_set4_a5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amedeo</th>\n",
       "      <td>0.023293</td>\n",
       "      <td>0.023293</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avogadro</th>\n",
       "      <td>0.153732</td>\n",
       "      <td>0.153732</td>\n",
       "      <td>0.156672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caricatur</th>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lorenzo</th>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>0.018618</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romano</th>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniondal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cve</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lha</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peanut</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pepperidg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27374 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           S08_set4_a8  S09_set4_a8  S10_set4_a8  S10_set5_a5  S08_set3_a7  \\\n",
       "amedeo        0.023293     0.023293     0.015667     0.000000     0.000000   \n",
       "avogadro      0.153732     0.153732     0.156672     0.000000     0.000000   \n",
       "caricatur     0.004137     0.004137     0.000000     0.000725     0.000458   \n",
       "lorenzo       0.003768     0.003768     0.004224     0.000000     0.000000   \n",
       "romano        0.004372     0.004372     0.004901     0.000000     0.000000   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "uniondal      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "cve           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "lha           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "peanut        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "pepperidg     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "           S10_set6_a3  S10_set6_a2  S09_set3_a4  S09_set1_a5  S08_set2_a7  \\\n",
       "amedeo        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "avogadro      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "caricatur     0.000743     0.000000     0.000000     0.000000     0.000000   \n",
       "lorenzo       0.006088     0.018618     0.001482     0.001619     0.000000   \n",
       "romano        0.000000     0.000000     0.000000     0.000000     0.001165   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "uniondal      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "cve           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "lha           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "peanut        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "pepperidg     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "           ...  S10_set2_a4  S08_set1_a9  S08_set1_a8  S09_set2_a4  \\\n",
       "amedeo     ...          0.0          0.0          0.0          0.0   \n",
       "avogadro   ...          0.0          0.0          0.0          0.0   \n",
       "caricatur  ...          0.0          0.0          0.0          0.0   \n",
       "lorenzo    ...          0.0          0.0          0.0          0.0   \n",
       "romano     ...          0.0          0.0          0.0          0.0   \n",
       "...        ...          ...          ...          ...          ...   \n",
       "uniondal   ...          0.0          0.0          0.0          0.0   \n",
       "cve        ...          0.0          0.0          0.0          0.0   \n",
       "lha        ...          0.0          0.0          0.0          0.0   \n",
       "peanut     ...          0.0          0.0          0.0          0.0   \n",
       "pepperidg  ...          0.0          0.0          0.0          0.0   \n",
       "\n",
       "           S08_set2_a3  S09_set1_a1  S09_set3_a6  S09_set3_a2  S09_set4_a5  \\\n",
       "amedeo             0.0          0.0          0.0     0.000000          0.0   \n",
       "avogadro           0.0          0.0          0.0     0.000000          0.0   \n",
       "caricatur          0.0          0.0          0.0     0.000000          0.0   \n",
       "lorenzo            0.0          0.0          0.0     0.000000          0.0   \n",
       "romano             0.0          0.0          0.0     0.000000          0.0   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "uniondal           0.0          0.0          0.0     0.020807          0.0   \n",
       "cve                0.0          0.0          0.0     0.010404          0.0   \n",
       "lha                0.0          0.0          0.0     0.010404          0.0   \n",
       "peanut             0.0          0.0          0.0     0.010404          0.0   \n",
       "pepperidg          0.0          0.0          0.0     0.010404          0.0   \n",
       "\n",
       "           S08_set4_a5  \n",
       "amedeo             0.0  \n",
       "avogadro           0.0  \n",
       "caricatur          0.0  \n",
       "lorenzo            0.0  \n",
       "romano             0.0  \n",
       "...                ...  \n",
       "uniondal           0.0  \n",
       "cve                0.0  \n",
       "lha                0.0  \n",
       "peanut             0.0  \n",
       "pepperidg          0.0  \n",
       "\n",
       "[27374 rows x 150 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_docs_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS USER QUERY\n",
    "\n",
    "test_query = \"Was Abraham Lincoln the sixteenth President of the United States?\"\n",
    "\n",
    "tokenize(test_query)\n",
    "\n",
    "def vectorise_query(user_query, corpus_vector): # corpus vector = tf_idf dataframe\n",
    "     corpus_vector[\"query_vector\"] = pd.Series(0.0, index=corpus_vector.index)\n",
    "     tokenized_query = tokenize(user_query)\n",
    "     counts = Counter(tokenized_query)\n",
    "     query_length = len(tokenized_query)\n",
    "     for term, freq in counts.items():\n",
    "          if term in corpus_vector.index:\n",
    "               # calculate tf_idf\n",
    "               corpus_vector[\"query_vector\"][term] = freq/query_length * idf_scores[term] # or use another tf scheme\n",
    "     return corpus_vector[\"query_vector\"]\n",
    "\n",
    "\n",
    "tf_idf_docs_vector.index\n",
    "\n",
    "query_vector = vectorise_query(test_query, corpus_vector=tf_idf_docs_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c78c4048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S08_set3_a4': 0.569014664937743,\n",
       " 'S08_set3_a5': 0.08433460585753316,\n",
       " 'S08_set3_a3': 0.05324577786464507,\n",
       " 'S08_set3_a7': 0.04099654074145948,\n",
       " 'S08_set3_a10': 0.03345029378342844,\n",
       " 'S08_set3_a8': 0.03189705635185302,\n",
       " 'S08_set3_a6': 0.027862153037531385,\n",
       " 'S08_set3_a1': 0.02670772686750019,\n",
       " 'S08_set3_a2': 0.023130640278709966,\n",
       " 'S08_set3_a9': 0.01645035150762555,\n",
       " 'S08_set2_a10': 0.01319870788669934,\n",
       " 'S10_set3_a8': 0.01227799562181076,\n",
       " 'S08_set2_a5': 0.01180678012546664,\n",
       " 'S08_set2_a4': 0.011155391704735167,\n",
       " 'S08_set4_a10': 0.010617516245987136,\n",
       " 'S09_set4_a10': 0.010617516245987136,\n",
       " 'S10_set4_a10': 0.008411108543030494,\n",
       " 'S08_set2_a6': 0.007904285606592181,\n",
       " 'S10_set3_a4': 0.006860133570075575,\n",
       " 'S08_set2_a8': 0.005859058108080097,\n",
       " 'S10_set3_a10': 0.005283473584768396,\n",
       " 'S08_set4_a4': 0.005011270994477851,\n",
       " 'S09_set4_a4': 0.005011270994477851,\n",
       " 'S10_set4_a4': 0.004828706725192817,\n",
       " 'S08_set2_a9': 0.00465042561506945,\n",
       " 'S09_set1_a5': 0.004505955074164989,\n",
       " 'S10_set3_a6': 0.004063880690776493,\n",
       " 'S08_set2_a7': 0.003777694880444555,\n",
       " 'S10_set1_a5': 0.00352674754310466,\n",
       " 'S09_set3_a4': 0.003289144330674892,\n",
       " 'S10_set5_a1': 0.0030620176832080893,\n",
       " 'S10_set2_a9': 0.0030292278573236754,\n",
       " 'S09_set2_a9': 0.0030292278573236754,\n",
       " 'S09_set5_a1': 0.002993454721315547,\n",
       " 'S09_set5_a8': 0.0022349931524818065,\n",
       " 'S08_set2_a2': 0.002120573611645379,\n",
       " 'S09_set5_a6': 0.0020200301291308197,\n",
       " 'S10_set3_a1': 0.0019067947949496491,\n",
       " 'S09_set3_a5': 0.0019027199060151366,\n",
       " 'S10_set3_a5': 0.0017649195266039636,\n",
       " 'S10_set3_a9': 0.001585290482597279,\n",
       " 'S08_set2_a1': 0.0014694496113537038,\n",
       " 'S08_set1_a4': 0.0012969742138191338,\n",
       " 'S10_set1_a4': 0.0012149861878873946,\n",
       " 'S09_set5_a2': 0.0010694319700698157,\n",
       " 'S10_set6_a4': 0.001065920259625828,\n",
       " 'S09_set4_a3': 0.0010543055738023103,\n",
       " 'S08_set4_a3': 0.0010543055738023103,\n",
       " 'S09_set5_a9': 0.001031055878453678,\n",
       " 'S09_set3_a3': 0.001000270053558635,\n",
       " 'S09_set3_a9': 0.0009871467158601328,\n",
       " 'S10_set6_a10': 0.0009184379555300708,\n",
       " 'S10_set4_a3': 0.0009006259069120995,\n",
       " 'S09_set5_a5': 0.0008542832309539407,\n",
       " 'S10_set5_a8': 0.0007812096308979285,\n",
       " 'S10_set3_a7': 0.0007736074499645273,\n",
       " 'S08_set4_a7': 0.0007661629411376626,\n",
       " 'S09_set4_a7': 0.0007661629411376626,\n",
       " 'S09_set3_a2': 0.0006942277742526646,\n",
       " 'S09_set4_a1': 0.0006847142701686081,\n",
       " 'S08_set4_a1': 0.0006847142701686081,\n",
       " 'S10_set4_a7': 0.0006672268206492239,\n",
       " 'S09_set3_a7': 0.000549283815904278,\n",
       " 'S09_set3_a1': 0.0005433660251730558,\n",
       " 'S10_set3_a2': 0.0005404899619050931,\n",
       " 'S10_set4_a9': 0.0005353573734360943,\n",
       " 'S10_set1_a2': 0.0005219137280635222,\n",
       " 'S08_set2_a3': 0.0005028202493801947,\n",
       " 'S10_set4_a1': 0.0004908363926216972,\n",
       " 'S10_set6_a8': 0.0004629189097014231,\n",
       " 'S08_set4_a9': 0.00039901863378955324,\n",
       " 'S09_set4_a9': 0.00039901863378955324,\n",
       " 'S08_set4_a6': 0.00036169879911902457,\n",
       " 'S09_set4_a6': 0.00036169879911902457,\n",
       " 'S09_set5_a10': 0.0003448332607543331,\n",
       " 'S10_set4_a6': 0.00033439727469118777,\n",
       " 'S10_set4_a2': 0.00032232368380903507,\n",
       " 'S10_set3_a3': 0.0002892749293257659,\n",
       " 'S10_set5_a7': 0.00028165142375388225,\n",
       " 'S10_set1_a7': 0.00027889304216895263,\n",
       " 'S09_set5_a7': 0.0002695878435176403,\n",
       " 'S10_set5_a6': 0.000268318351126075,\n",
       " 'S10_set6_a9': 0.00023777559453883032,\n",
       " 'S08_set4_a2': 0.00023503025250897183,\n",
       " 'S09_set4_a2': 0.00023503025250897183,\n",
       " 'S09_set1_a6': 0.00020765131787861955,\n",
       " 'S09_set1_a9': 0.0002049200329823839,\n",
       " 'S09_set1_a4': 0.0002049200329823839,\n",
       " 'S10_set1_a8': 0.00020010238394511693,\n",
       " 'S10_set1_a3': 0.00019836144302988676,\n",
       " 'S10_set5_a10': 0.0001885223051041122,\n",
       " 'S10_set5_a9': 0.00018782856929319304,\n",
       " 'S10_set6_a1': 0.00018324256372595542,\n",
       " 'S09_set1_a2': 0.00015860163771107852,\n",
       " 'S10_set5_a3': 0.00015175373155016376,\n",
       " 'S09_set5_a3': 0.00014917998565149856,\n",
       " 'S10_set4_a8': 0.00014621415223041863,\n",
       " 'S09_set1_a10': 0.00013366260599040716,\n",
       " 'S09_set1_a1': 0.00012301000822225694,\n",
       " 'S09_set1_a3': 0.00011781661560831897,\n",
       " 'S10_set6_a7': 0.00011496228195511559,\n",
       " 'S09_set5_a4': 0.0001118488926004934,\n",
       " 'S08_set1_a8': 0.00010736628147723078,\n",
       " 'S08_set1_a6': 0.00010156717541974382,\n",
       " 'S09_set2_a1': 9.669838245821216e-05,\n",
       " 'S10_set2_a1': 9.669838245821216e-05,\n",
       " 'S10_set2_a7': 9.26180564053666e-05,\n",
       " 'S09_set2_a7': 9.26180564053666e-05,\n",
       " 'S09_set3_a6': 9.05245419046521e-05,\n",
       " 'S08_set1_a5': 8.84163816341253e-05,\n",
       " 'S08_set1_a3': 8.289825390205496e-05,\n",
       " 'S10_set5_a5': 6.843562866960268e-05,\n",
       " 'S09_set3_a8': 6.82345804867855e-05,\n",
       " 'S08_set4_a8': 6.781106588007924e-05,\n",
       " 'S09_set4_a8': 6.781106588007924e-05,\n",
       " 'S09_set1_a8': 6.089954653010762e-05,\n",
       " 'S10_set1_a10': 5.534272299121175e-05,\n",
       " 'S10_set1_a1': 5.46195772522756e-05,\n",
       " 'S10_set5_a4': 4.867801698030742e-05,\n",
       " 'S10_set6_a3': 4.4015691077549344e-05,\n",
       " 'S10_set1_a6': 3.858800416099606e-05,\n",
       " 'S10_set2_a4': 3.585430840253904e-05,\n",
       " 'S09_set2_a4': 3.585430840253904e-05,\n",
       " 'S10_set5_a2': 3.514509009674957e-05,\n",
       " 'S08_set1_a2': 2.8021698498212614e-05,\n",
       " 'S08_set1_a1': 2.7040626147176722e-05,\n",
       " 'S10_set6_a6': 2.2992952308645654e-05,\n",
       " 'S09_set3_a10': 2.0351781358830717e-05,\n",
       " 'S10_set6_a2': 1.9970896164255438e-05,\n",
       " 'S09_set2_a2': 1.5889616022159925e-05,\n",
       " 'S10_set2_a2': 1.5889616022159925e-05,\n",
       " 'S10_set2_a5': 0.0,\n",
       " 'S09_set4_a5': 0.0,\n",
       " 'S10_set6_a5': 0.0,\n",
       " 'S09_set1_a7': 0.0,\n",
       " 'S10_set2_a6': 0.0,\n",
       " 'S08_set1_a9': 0.0,\n",
       " 'S10_set2_a3': 0.0,\n",
       " 'S09_set2_a6': 0.0,\n",
       " 'S08_set1_a7': 0.0,\n",
       " 'S09_set2_a3': 0.0,\n",
       " 'S10_set1_a9': 0.0,\n",
       " 'S08_set4_a5': 0.0,\n",
       " 'S09_set2_a8': 0.0,\n",
       " 'S10_set2_a8': 0.0,\n",
       " 'S08_set1_a10': 0.0,\n",
       " 'S09_set2_a5': 0.0,\n",
       " 'S10_set4_a5': 0.0,\n",
       " 'S10_set2_a10': 0.0,\n",
       " 'S09_set2_a10': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COSINE SIMILARITY - method to compare the query with each document in the corpus\n",
    "\n",
    "def calculate_cosine_similiarity(vocab_index, doc_index, query_scores):\n",
    "     \"\"\"calculate cosine similarity in order to compare query vector with document vector\"\"\"\n",
    "     cosine_scores = {}\n",
    "     query_scalar = np.sqrt(sum(vocab_index[query_scores] ** 2))\n",
    "     for doc in doc_index:\n",
    "          doc_scalar = np.sqrt(sum(vocab_index[doc] ** 2))\n",
    "          dot_prod = sum(vocab_index[doc] * vocab_index[query_scores])\n",
    "          cosine = (dot_prod / (query_scalar * doc_scalar))\n",
    "          cosine_scores[doc] = cosine\n",
    "     # sorted cosine scores by cosine score value\n",
    "     sorted_cosine_scores = {key: value for key, value in sorted(cosine_scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "     return sorted_cosine_scores\n",
    "\n",
    "\n",
    "cosine_scores = calculate_cosine_similiarity(tf_idf_docs_vector, doc_ids, 'query_vector')\n",
    "cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5643c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S09_set2_a1', 'S10_set2_a1']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cosine similarity values across all documents given query vector \n",
    "top_cosine = list(calculate_cosine_similiarity(tf_idf_docs_vector, doc_ids, 'query_vector'))[0:2]\n",
    "\n",
    "top_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e510a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Question</th>\n",
       "      <th>CorrectArticleFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Did John Adams represent the Continental Congr...</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Did John Adams represent the Continental Congr...</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Was Adams raised Congregationalist?</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Was Adams raised Congregationalist?</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Was Adams an opponent of the Stamp Act?</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>Piano</td>\n",
       "      <td>Why are upright pianos more compact?</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>Piano</td>\n",
       "      <td>Do older pianos have more keys than modern pia...</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>Piano</td>\n",
       "      <td>Do older pianos have more keys than modern pia...</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Piano</td>\n",
       "      <td>What are the names of a piano's pedals?</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>Piano</td>\n",
       "      <td>What are the names of a piano's pedals?</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Topic                                           Question  \\\n",
       "859   John_Adams  Did John Adams represent the Continental Congr...   \n",
       "860   John_Adams  Did John Adams represent the Continental Congr...   \n",
       "861   John_Adams                Was Adams raised Congregationalist?   \n",
       "862   John_Adams                Was Adams raised Congregationalist?   \n",
       "863   John_Adams            Was Adams an opponent of the Stamp Act?   \n",
       "...          ...                                                ...   \n",
       "1108       Piano               Why are upright pianos more compact?   \n",
       "1109       Piano  Do older pianos have more keys than modern pia...   \n",
       "1110       Piano  Do older pianos have more keys than modern pia...   \n",
       "1111       Piano            What are the names of a piano's pedals?   \n",
       "1112       Piano            What are the names of a piano's pedals?   \n",
       "\n",
       "     CorrectArticleFile  \n",
       "859         S08_set3_a1  \n",
       "860         S08_set3_a1  \n",
       "861         S08_set3_a1  \n",
       "862         S08_set3_a1  \n",
       "863         S08_set3_a1  \n",
       "...                 ...  \n",
       "1108        S10_set2_a1  \n",
       "1109        S10_set2_a1  \n",
       "1110        S10_set2_a1  \n",
       "1111        S10_set2_a1  \n",
       "1112        S10_set2_a1  \n",
       "\n",
       "[259 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create subset of data for testing certain topics\n",
    "\n",
    "import csv\n",
    "\n",
    "# bring from different data subsets\n",
    "s08 = pd.read_csv(\"group_project/S08_question_answer_pairs.txt\", delimiter='\\t', encoding = \"latin-1\")\n",
    "s09 = pd.read_csv(\"group_project/S09_question_answer_pairs.txt\", delimiter='\\t', encoding = \"latin-1\")\n",
    "s10 = pd.read_csv(\"group_project/S10_question_answer_pairs.txt\", delimiter='\\t', encoding = \"latin-1\")\n",
    "\n",
    "chosen_cols = ['Topic', 'Question', 'Answer', 'DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'CorrectArticleFile']\n",
    "\n",
    "s08.columns = chosen_cols\n",
    "s09.columns = chosen_cols\n",
    "s10.columns = chosen_cols\n",
    "\n",
    "pd_lst = [s08, s09, s10]\n",
    "\n",
    "# merge into one questions list\n",
    "questions_lst = pd.concat(pd_lst)\n",
    "\n",
    "\n",
    "# take subset of questions for our sampling\n",
    "subset = questions_lst[['Topic', 'Question', 'CorrectArticleFile']]\n",
    "\n",
    "topics = ['kangaroo', 'Liechtenstein', 'John_Adams', 'Blaise_Pascal', 'Piano', 'London', 'English_Language', 'Pablo_Picasso']\n",
    "\n",
    "selected_questions = subset[subset['Topic'].isin(topics)]\n",
    "\n",
    "\n",
    "selected_questions # has columns \n",
    "\n",
    "\n",
    "#with open('test_questions.csv', 'w') as f:\n",
    "   # selected_questions.to_csv(f)\n",
    "\n",
    "selected_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3152864c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Did John Adams represent the Continental Congress in Europe?': 'S08_set3_a1',\n",
       " 'Was Adams raised Congregationalist?': 'S08_set3_a1',\n",
       " 'Was Adams an opponent of the Stamp Act?': 'S08_set3_a1',\n",
       " 'When did Adams graduate from college?': 'S08_set3_a1',\n",
       " 'Who was on the committee with Adams to draft  a Declaration of Independence?': 'S08_set3_a1',\n",
       " 'What did Jefferson call John Adams?': 'S08_set3_a1',\n",
       " \"What was Adams' political party?\": 'S08_set3_a1',\n",
       " 'Was Adams the first to introduce a bicameral legislature?': 'S08_set3_a1',\n",
       " 'Did John Adams get along with Alexander Hamilton?': 'S08_set3_a1',\n",
       " 'Did John Adams go to Harvard? ': 'S08_set3_a1',\n",
       " 'Did John Adams support the Stamp Act of 1765?': 'S08_set3_a1',\n",
       " \"Is Adams' birthplace part of a national park?\": 'S08_set3_a1',\n",
       " 'When did John Adams serve as Vice President?': 'S08_set3_a1',\n",
       " 'With what party did Adams run for presidency?': 'S08_set3_a1',\n",
       " 'Where is Adams buried?': 'S08_set3_a1',\n",
       " 'Who were the midnight judges?': 'S08_set3_a1',\n",
       " 'In what ways was Adams opposed by Anderw Hamilton?': 'S08_set3_a1',\n",
       " 'What information did he record in his diary?': 'S08_set3_a1',\n",
       " \"Who was defeated for re-election in the`` Revolution of 1800'' by Thomas Jefferson?\": 'S08_set3_a1',\n",
       " 'Who represented the Continental Congress in Europe?': 'S08_set3_a1',\n",
       " 'What is now part of Adams National Historical Park?': 'S08_set3_a1',\n",
       " 'Is it true that adams had spent some time as the ambassador?': 'S08_set3_a1',\n",
       " 'Is it true that massachuS08_setts sent him in 1774?': 'S08_set3_a1',\n",
       " 'Who did MassachuS08_setts send in 1774?': 'S08_set3_a1',\n",
       " 'Are his last words often quoted as \" Thomas Jefferson survives \" . ?': 'S08_set3_a1',\n",
       " 'The John Adams Library , housed at the Boston Public Library , contains what?': 'S08_set3_a1',\n",
       " \"Adams ' opponents were what?\": 'S08_set3_a1',\n",
       " 'Did the election of 1800 not become a bitter and volatile battle , with each side expressing extraordinary fear of the other party and its policies ?': 'S08_set3_a1',\n",
       " 'What happened in 1764?': 'S08_set3_a1',\n",
       " 'Is a kangaroo a reptile?': 'S08_set1_a1',\n",
       " 'Is a kangaroo on the Australian coat of arms?': 'S08_set1_a1',\n",
       " 'Was James Cook the first to record the name \"Kangooroo?\"': 'S08_set1_a1',\n",
       " 'What is a collective noun for kangaroos?': 'S08_set1_a1',\n",
       " 'Where do joeys complete postnatal development?': 'S08_set1_a1',\n",
       " 'What do kangaroos use for \"crawl-walking?\"': 'S08_set1_a1',\n",
       " 'Why do kangaroos have a wide bite?': 'S08_set1_a1',\n",
       " 'What is responsible for converting the hydrogen byproduct of fermentation into acetate?': 'S08_set1_a1',\n",
       " 'Are wild kangaroos shot for meat?': 'S08_set1_a1',\n",
       " 'Have kangaroos fared well since European S08_settlement?': 'S08_set1_a1',\n",
       " 'Do kangaroos have many natural predators?': 'S08_set1_a1',\n",
       " 'What is the average life expectancy of a kangaroo?': 'S08_set1_a1',\n",
       " 'When did the first official report of kangaroo blindness take place?': 'S08_set1_a1',\n",
       " 'What are vehicles that frequent isolated roads often fitted with?': 'S08_set1_a1',\n",
       " 'Do kangaroos eat plants?': 'S08_set1_a1',\n",
       " 'What are some extinct predators of the kangaroo?': 'S08_set1_a1',\n",
       " 'Is a Kangaroo a Marsupial?': 'S08_set1_a1',\n",
       " 'Is the kangaroo an herbivour?': 'S08_set1_a1',\n",
       " 'Are Kangaroos Shy?': 'S08_set1_a1',\n",
       " 'What method of locomotion do Kangaroos Use?': 'S08_set1_a1',\n",
       " 'What is a collective noun for a kangaroo?': 'S08_set1_a1',\n",
       " 'What is a roo?': 'S08_set1_a1',\n",
       " 'What is used to protect a vehicale from a Kangaroo?': 'S08_set1_a1',\n",
       " 'What method is used by Kangaroos to travel?': 'S08_set1_a1',\n",
       " 'Who asked a nearby local what the creatures were called?': 'S08_set1_a1',\n",
       " 'What are four species that are commonly referred to as kangaroos?': 'S08_set1_a1',\n",
       " 'Are kangaroos and wallabies adept swimmers?': 'S08_set1_a1',\n",
       " 'Are kangaroos farmed to any extent?': 'S08_set1_a1',\n",
       " 'Who also discovered that less than three percent of kangaroos exposed to the virus developed blindness ?': 'S08_set1_a1',\n",
       " 'Different species of kangaroos eat what?': 'S08_set1_a1',\n",
       " 'Have Kangaroos dazzled by headlights or startled by engine noise been known to leap in front of cars ?': 'S08_set1_a1',\n",
       " 'Is a collision with a vehicle capable of killing a kangaroo ?': 'S08_set1_a1',\n",
       " 'Was the game of Marn grook played using a ball made from kangaroo by the Kurnai people ?': 'S08_set1_a1',\n",
       " 'Have kangaroos large , powerful hind legs , large feet adapted for leaping , a long muscular tail for balance , and a small head ?': 'S08_set1_a1',\n",
       " \"Is a kangaroo a marsupial from the family macropodidae -LRB- macropods , meaning (`` ` large foot ('' ' -RRB-?\": 'S08_set1_a1',\n",
       " 'What kinds of changes have larger kangaroos adapted much better to?': 'S08_set1_a1',\n",
       " 'Have larger kangaroos adapted much better to changes?': 'S08_set1_a1',\n",
       " 'Is Liechtenstein bordered by Switzerland?': 'S08_set2_a1',\n",
       " 'Is Liechtenstein the smallest German-speaking country in the world?': 'S08_set2_a1',\n",
       " 'Was Liechtenstein part of the ancient Roman province of Raetia?': 'S08_set2_a1',\n",
       " 'When was the first factory opened?': 'S08_set2_a1',\n",
       " 'How many municipalities is Liechtenstein divided into?': 'S08_set2_a1',\n",
       " 'What is the national currency of Liechtenstein?': 'S08_set2_a1',\n",
       " \"Has Leichtenstein worked to promote the county's image by prosecuting international money-laundering?\": 'S08_set2_a1',\n",
       " \"What company administers Leichtenstein's railways?\": 'S08_set2_a1',\n",
       " \"What percentage of Liechtenstein's population is foreign-born?\": 'S08_set2_a1',\n",
       " 'Is there an airport in Liechtenstein?': 'S08_set2_a1',\n",
       " 'Is Liechtenstein heavily urbanized?': 'S08_set2_a1',\n",
       " 'Is Liechtenstein doubly landlocked?': 'S08_set2_a1',\n",
       " 'Does Liechtenstein have an army?': 'S08_set2_a1',\n",
       " \"When was Liechtenstein's current constitution adopted?\": 'S08_set2_a1',\n",
       " 'What is the official language of Liechtenstein?': 'S08_set2_a1',\n",
       " 'What countries border Liechtenstein?': 'S08_set2_a1',\n",
       " 'What Roman province was Liechtenstein part of?': 'S08_set2_a1',\n",
       " 'How many municipalities are within Oberland?': 'S08_set2_a1',\n",
       " 'What is the smallest German-speaking country in the world?': 'S08_set2_a1',\n",
       " 'The Savings and Loans Bank was founded, as was the first cotton-weaving mill in what year?': 'S08_set2_a1',\n",
       " \"What enjoys one of the world's highest standards of living?\": 'S08_set2_a1',\n",
       " 'Does the state court rule on the conformity of laws?': 'S08_set2_a1',\n",
       " 'What do most recognizable international company and largest employer have in common?': 'S08_set2_a1',\n",
       " 'Was Liechtenstein completed in November 2000?': 'S08_set2_a1',\n",
       " 'What completed in November?': 'S08_set2_a1',\n",
       " 'The State Court rules what?': 'S08_set2_a1',\n",
       " 'The Historical Society of the Principality of Liechtenstein plays what?': 'S08_set2_a1',\n",
       " 'Is the museum collection also the national art collection of Liechtenstein ?': 'S08_set2_a1',\n",
       " 'Is there a small heliport at Balzers in Liechtenstein available for charter helicopter flights ?': 'S08_set2_a1',\n",
       " 'Are nationals referred to by the plural : Liechtensteiners ?': 'S08_set2_a1',\n",
       " 'Is it a winter sports resort , although it is perhaps best known as a tax haven ?': 'S08_set2_a1',\n",
       " 'Is it a winter sports resort?': 'S08_set2_a1',\n",
       " 'Is it the smallest german-speaking country in the world?': 'S08_set2_a1',\n",
       " 'What happened in moravia , lower austria , silesia , and styria , though in all cases , these territories were held in fief under other more senior feudal lords?': 'S08_set2_a1',\n",
       " 'Was Blaise Pascal a mathematician of the first order?': 'S09_set4_a4',\n",
       " 'Could Blaise Pascal move without crutches?': 'S09_set4_a4',\n",
       " 'Has the name Pascal been given to the SI unit of pressure?': 'S09_set4_a4',\n",
       " 'From what did Pascal suffer throughout his life?': 'S09_set4_a4',\n",
       " 'What did Pascal argue was as perfect as possible?': 'S09_set4_a4',\n",
       " 'What is the best physician?': 'S09_set4_a4',\n",
       " 'Who was the eldest sibling?': 'S09_set4_a4',\n",
       " \"Aside from the Provincial Letters' religious influence, were they popular as a literary work?\": 'S09_set4_a4',\n",
       " 'Of whose continual poor health was the cause never precisely determined?': 'S09_set4_a4',\n",
       " 'Is London the capital of the United Kingdom?': 'S09_set3_a1',\n",
       " \"Does London's population draw from a wide range of religions?\": 'S09_set3_a1',\n",
       " 'Did Caunte take control of the English throne in 101?': 'S09_set3_a1',\n",
       " 'Over how many languages are spoken in London?': 'S09_set3_a1',\n",
       " 'What had the Anglo-Saxons created by the 600s?': 'S09_set3_a1',\n",
       " 'What city in the UK has been subjected to bouts of terrorism?': 'S09_set3_a1',\n",
       " 'What countries did James VI of Scotland unite?': 'S09_set3_a1',\n",
       " 'How did civil wars affect England during the Middle Ages?': 'S09_set3_a1',\n",
       " \"Who was Blaise Pascal's father?\": 'S10_set4_a4',\n",
       " 'Was Pascal a French mathematician?': 'S10_set4_a4',\n",
       " 'Did Pascal have poor health throughout his life?': 'S10_set4_a4',\n",
       " 'How old was Pascal when he lost his mother?': 'S10_set4_a4',\n",
       " \"Who was Pascal's younger sister?\": 'S10_set4_a4',\n",
       " 'What led Pascal to his religious conversion?': 'S10_set4_a4',\n",
       " 'How old was Pascal when he died?': 'S10_set4_a4',\n",
       " 'Did Pascal write about cycloid before 1658?': 'S10_set4_a4',\n",
       " 'Is there a programming language called Pascal?': 'S10_set4_a4',\n",
       " 'Crowds of believers came to see and kiss the thorn; all of Catholic where acclaimed a miracle?': 'S10_set4_a4',\n",
       " \"Wasn't Blaise Pascal a work of Desargues on conic sections?\": 'S10_set4_a4',\n",
       " 'Who died the next morning?': 'S10_set4_a4',\n",
       " 'When did his father die?': 'S10_set4_a4',\n",
       " 'Was he a child prodigy who was educated by his father, a civil servant?': 'S10_set4_a4',\n",
       " \"Was Pascal's earliest work in the natural and applied sciences where he made important contributions to the construction of mechanical calculators, the study of fluids, and clarified the concepts of pressure and vacuum by generalizing the work of Evangelista Torricelli?\": 'S10_set4_a4',\n",
       " 'Did Pascal also write in defense of the scientific method?': 'S10_set4_a4',\n",
       " 'What happened in 1968 through 1971?': 'S10_set6_a1',\n",
       " 'What happened in 1838?': 'S10_set6_a1',\n",
       " 'Who was not long in finding another lover, Jacqueline Roque?': 'S10_set6_a1',\n",
       " 'When did Picasso make his first trip to Paris?': 'S10_set6_a1',\n",
       " 'Give an example of the most comprehensive records extant of any major artists beginnings. ': 'S10_set6_a1',\n",
       " 'Is in the 1996 movie Surviving Picasso Picasso played by actor Anthony Hopkins?': 'S10_set6_a1',\n",
       " 'Is the U.S. copyright representative for the Picasso Administration the Artists Rights Society?': 'S10_set6_a1',\n",
       " 'Is he one of the most recognized figures in 20th-century art?': 'S10_set6_a1',\n",
       " 'Is he best known for co-founding the Cubist movement and for the wide variety of styles embodied in his work?': 'S10_set6_a1',\n",
       " \"Are among his most famous works the proto-Cubist Les Demoiselles d'Avignon (1907) and Guernica (1937), his portrayal of the German bombing of Guernica during the Spanish Civil War?\": 'S10_set6_a1',\n",
       " 'Are pianos used in Western music?': 'S10_set2_a1',\n",
       " 'Are \"upright pianos\" called \"vertical pianos\"?': 'S10_set2_a1',\n",
       " 'Did Bartolomeo Cristofori invent the modern piano?': 'S10_set2_a1',\n",
       " 'What is the middle pedal called on grand pianos?': 'S10_set2_a1',\n",
       " 'How many black keys do modern pianos have?': 'S10_set2_a1',\n",
       " 'What is the sustain pedal called?': 'S10_set2_a1',\n",
       " \"Where is Irving Berlin's piano located?\": 'S10_set2_a1',\n",
       " 'What kind of piano did Irving Berlin play?': 'S10_set2_a1',\n",
       " 'Is the left-most pedal on a grand piano called the una corda?': 'S10_set2_a1',\n",
       " \"Is it advantageous for a grand piano's metal plate to be quite massive?\": 'S10_set2_a1',\n",
       " 'Is the mechanism in an upright piano perpendicular to its keys?': 'S10_set2_a1',\n",
       " 'About how tall is a typical studio piano?': 'S10_set2_a1',\n",
       " \"What are a piano's keys generally made of?\": 'S10_set2_a1',\n",
       " 'How many total keys does a typical modern piano have?': 'S10_set2_a1',\n",
       " 'Why are upright pianos more compact?': 'S10_set2_a1',\n",
       " 'Do older pianos have more keys than modern pianos?': 'S10_set2_a1',\n",
       " \"What are the names of a piano's pedals?\": 'S10_set2_a1'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of questions and their corresponding document ids\n",
    "\n",
    "convert_to_dict = selected_questions.to_dict(orient='records')\n",
    "\n",
    "selected_question_doc_pairs = {entry['Question']: entry['CorrectArticleFile'] for entry in convert_to_dict}\n",
    "\n",
    "selected_question_doc_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bfd5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare output of tf_idf baseline with gold standard\n",
    "\n",
    "queries = list(i for i in selected_question_doc_pairs.keys())\n",
    "\n",
    "documents = list(selected_question_doc_pairs.values())\n",
    "\n",
    "top_cosine_1= {}\n",
    "top_cosines_2 = {}\n",
    "\n",
    "for query, document in selected_question_doc_pairs.items():\n",
    "    query_vector = vectorise_query(query, corpus_vector=tf_idf_docs_vector)\n",
    "    cosine_scores = calculate_cosine_similiarity(tf_idf_docs_vector, doc_ids, 'query_vector')\n",
    "    top_1 = list(cosine_scores)[0]\n",
    "    top_2 = list(cosine_scores)[0:2]\n",
    "    top_cosine_1[query] = top_1\n",
    "    top_cosines_2[query] = top_2\n",
    "\n",
    "\n",
    "# retrieve results@1\n",
    "top_cosine_1_df = pd.DataFrame(top_cosine_1.items(), columns=[\"Question\", \"File Name\"])\n",
    "top_cosine_1_df.columns = ['Question', 'DocumentRetrieved']\n",
    "    \n",
    "# retrieve results@2\n",
    "top_cosines_2_df = pd.DataFrame(top_cosines_2.items(), columns=[\"Question\", \"File Name\"])\n",
    "top_cosines_2_df.columns = ['Question', 'DocumentRetrieved']\n",
    "\n",
    "with open('top_1.csv', 'w') as f:\n",
    "    top_cosine_1_df.to_csv(f)\n",
    "\n",
    "with open('top_2.csv', 'w') as f:\n",
    "    top_cosines_2_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8c86673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#with open('documents_retrieved.csv', 'w') as f:\n",
    "    #top_cosines_df.to_csv(f)\n",
    "\n",
    "final_lst_1 = pd.merge(selected_questions, top_cosine_1_df)\n",
    "\n",
    "final_lst_2 = pd.merge(selected_questions, top_cosines_2_df)\n",
    "\n",
    "final_lst_1['Match'] = final_lst_1.apply(lambda row: 1 if row['CorrectArticleFile'] == row['DocumentRetrieved'] else 0, axis=1)\n",
    "\n",
    "final_lst_2['Match'] = final_lst_2.apply(lambda row: 1 if row['CorrectArticleFile'] in row['DocumentRetrieved'] else 0, axis=1)\n",
    "\n",
    "with open('final_results_1.csv', 'w') as f:\n",
    "    final_lst_1.to_csv(f)\n",
    "\n",
    "with open('final_results_2.csv', 'w') as f:\n",
    "    final_lst_2.to_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98b574bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Question</th>\n",
       "      <th>CorrectArticleFile</th>\n",
       "      <th>DocumentRetrieved</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Did John Adams represent the Continental Congr...</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "      <td>['S08_set3_a1', 'S08_set3_a2']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Did John Adams represent the Continental Congr...</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "      <td>['S08_set3_a1', 'S08_set3_a2']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Was Adams raised Congregationalist?</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "      <td>['S08_set3_a1', 'S08_set3_a2']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Was Adams raised Congregationalist?</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "      <td>['S08_set3_a1', 'S08_set3_a2']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John_Adams</td>\n",
       "      <td>Was Adams an opponent of the Stamp Act?</td>\n",
       "      <td>S08_set3_a1</td>\n",
       "      <td>['S08_set3_a1', 'S08_set3_a2']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Piano</td>\n",
       "      <td>Why are upright pianos more compact?</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "      <td>['S09_set2_a1', 'S10_set2_a1']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Piano</td>\n",
       "      <td>Do older pianos have more keys than modern pia...</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "      <td>['S09_set2_a1', 'S10_set2_a1']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Piano</td>\n",
       "      <td>Do older pianos have more keys than modern pia...</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "      <td>['S09_set2_a1', 'S10_set2_a1']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Piano</td>\n",
       "      <td>What are the names of a piano's pedals?</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "      <td>['S09_set2_a1', 'S10_set2_a1']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Piano</td>\n",
       "      <td>What are the names of a piano's pedals?</td>\n",
       "      <td>S10_set2_a1</td>\n",
       "      <td>['S09_set2_a1', 'S10_set2_a1']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Topic                                           Question  \\\n",
       "0    John_Adams  Did John Adams represent the Continental Congr...   \n",
       "1    John_Adams  Did John Adams represent the Continental Congr...   \n",
       "2    John_Adams                Was Adams raised Congregationalist?   \n",
       "3    John_Adams                Was Adams raised Congregationalist?   \n",
       "4    John_Adams            Was Adams an opponent of the Stamp Act?   \n",
       "..          ...                                                ...   \n",
       "254       Piano               Why are upright pianos more compact?   \n",
       "255       Piano  Do older pianos have more keys than modern pia...   \n",
       "256       Piano  Do older pianos have more keys than modern pia...   \n",
       "257       Piano            What are the names of a piano's pedals?   \n",
       "258       Piano            What are the names of a piano's pedals?   \n",
       "\n",
       "    CorrectArticleFile               DocumentRetrieved  Match  \n",
       "0          S08_set3_a1  ['S08_set3_a1', 'S08_set3_a2']      1  \n",
       "1          S08_set3_a1  ['S08_set3_a1', 'S08_set3_a2']      1  \n",
       "2          S08_set3_a1  ['S08_set3_a1', 'S08_set3_a2']      1  \n",
       "3          S08_set3_a1  ['S08_set3_a1', 'S08_set3_a2']      1  \n",
       "4          S08_set3_a1  ['S08_set3_a1', 'S08_set3_a2']      1  \n",
       "..                 ...                             ...    ...  \n",
       "254        S10_set2_a1  ['S09_set2_a1', 'S10_set2_a1']      1  \n",
       "255        S10_set2_a1  ['S09_set2_a1', 'S10_set2_a1']      1  \n",
       "256        S10_set2_a1  ['S09_set2_a1', 'S10_set2_a1']      1  \n",
       "257        S10_set2_a1  ['S09_set2_a1', 'S10_set2_a1']      1  \n",
       "258        S10_set2_a1  ['S09_set2_a1', 'S10_set2_a1']      1  \n",
       "\n",
       "[259 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alt code: load evaluation matrix with manually updated values (since duplicate files are in the data)\n",
    "import pandas as pd\n",
    "\n",
    "with open('final_results_1.csv') as f:\n",
    "    retrieval_1 = pd.read_csv(f, index_col=0)\n",
    "\n",
    "retrieval_1\n",
    "\n",
    "with open('final_results_2.csv') as f:\n",
    "    retrieval_2 = pd.read_csv(f, index_col=0)\n",
    "\n",
    "retrieval_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score k@1 is: 0.833976833976834\n",
      "Precision score k@2 is: 0.8725868725868726\n"
     ]
    }
   ],
   "source": [
    "# measure precision using Match column in results df\n",
    "\n",
    "\n",
    "#k@1\n",
    "count_match_1 = retrieval_1['Match'].value_counts()[1]\n",
    "count_fail_1 = retrieval_1['Match'].value_counts()[0]\n",
    "\n",
    "precision_1 = count_match_1/(count_match_1+count_fail_1)\n",
    "\n",
    "#k@2\n",
    "count_match_2 = retrieval_2['Match'].value_counts()[1]\n",
    "count_fail_2 = retrieval_2['Match'].value_counts()[0]\n",
    "\n",
    "precision_2 = count_match_2/(count_match_2+count_fail_2)\n",
    "\n",
    "\n",
    "print(f\"Precision score k@1 is: {precision_1}\")\n",
    "print(f\"Precision score k@2 is: {precision_2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
